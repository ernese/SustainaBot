{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator Dimension Processor (Fixed)\n",
    "\n",
    "Creates the indicator dimension table for the Philippine socioeconomic data medallion architecture.\n",
    "Extracts and standardizes indicator metadata from all bronze layer Delta tables.\n",
    "\n",
    "**Output**: `dim_indicator` with comprehensive indicator metadata and categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/08/18 21:50:20 WARN Utils: Your hostname, 3rnese resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/08/18 21:50:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ernese/miniconda3/envs/SO/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ernese/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ernese/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-413e9499-b8a8-4abe-bc70-0ea3e455f1fe;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 119ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-413e9499-b8a8-4abe-bc70-0ea3e455f1fe\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "25/08/18 21:50:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.4.0\n",
      "Application: IndicatorDimensionProcessor\n",
      "Delta Lake support: io.delta.sql.DeltaSparkSessionExtension\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session with proper Delta Lake configuration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IndicatorDimensionProcessor\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Application: {spark.sparkContext.appName}\")\n",
    "print(f\"Delta Lake support: {spark.conf.get('spark.sql.extensions')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze Path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-bronze\n",
      "Silver Path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver\n",
      "Processing Time: 2025-08-18 21:50:23.162899\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BRONZE_PATH = \"/home/ernese/miniconda3/envs/SO/New_SO/final-spark-bronze\"\n",
    "SILVER_PATH = \"/home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver\"\n",
    "PROCESSING_TIMESTAMP = datetime.now()\n",
    "\n",
    "os.makedirs(SILVER_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Bronze Path: {BRONZE_PATH}\")\n",
    "print(f\"Silver Path: {SILVER_PATH}\")\n",
    "print(f\"Processing Time: {PROCESSING_TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Default Philippine Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 15 default Philippine indicators\n",
      "\n",
      "Category distribution:\n",
      "  Consumption: 1\n",
      "  Demographics: 1\n",
      "  Emissions: 1\n",
      "  Employment: 2\n",
      "  EnergyConsumption: 1\n",
      "  EnergyPricing: 1\n",
      "  Hydropower: 1\n",
      "  Pollution: 1\n",
      "  Poverty: 1\n",
      "  TourismEconomics: 1\n",
      "  TourismExpenditure: 1\n",
      "  VitalStatistics: 2\n",
      "  Wages: 1\n",
      "\n",
      "Data source distribution:\n",
      "  DOE: 3\n",
      "  PSA: 12\n",
      "\n",
      "Frequency distribution:\n",
      "  Annual: 8\n",
      "  Daily: 1\n",
      "  Monthly: 2\n",
      "  Quarterly: 4\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive default Philippine indicators\n",
    "def create_default_philippine_indicators():\n",
    "    \"\"\"Create default Philippine socioeconomic indicators\"\"\"\n",
    "    indicators = [\n",
    "        # Demographics\n",
    "        {\n",
    "            'code': 'PSA_POP_TOTAL',\n",
    "            'name': 'Total Population',\n",
    "            'category': 'Demographics',\n",
    "            'subcategory': None,\n",
    "            'unit': 'Count (Persons/Units)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_BIRTHS_TOTAL',\n",
    "            'name': 'Total Live Births',\n",
    "            'category': 'VitalStatistics',\n",
    "            'subcategory': 'Births',\n",
    "            'unit': 'Count (Persons/Units)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_DEATHS_TOTAL',\n",
    "            'name': 'Total Deaths',\n",
    "            'category': 'VitalStatistics',\n",
    "            'subcategory': 'Deaths',\n",
    "            'unit': 'Count (Persons/Units)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        \n",
    "        # Labor\n",
    "        {\n",
    "            'code': 'PSA_EMPLOYMENT_RATE',\n",
    "            'name': 'Employment Rate',\n",
    "            'category': 'Employment',\n",
    "            'subcategory': 'Employment',\n",
    "            'unit': 'Percentage',\n",
    "            'frequency': 'Quarterly',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_UNEMPLOYMENT_RATE',\n",
    "            'name': 'Unemployment Rate',\n",
    "            'category': 'Employment',\n",
    "            'subcategory': 'Unemployment',\n",
    "            'unit': 'Percentage',\n",
    "            'frequency': 'Quarterly',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_DAILY_WAGE',\n",
    "            'name': 'Average Daily Basic Pay',\n",
    "            'category': 'Wages',\n",
    "            'subcategory': 'Wages',\n",
    "            'unit': 'Currency (PHP/USD)',\n",
    "            'frequency': 'Monthly',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        \n",
    "        # Energy\n",
    "        {\n",
    "            'code': 'DOE_ENERGY_CONSUMPTION',\n",
    "            'name': 'Total Final Energy Consumption',\n",
    "            'category': 'EnergyConsumption',\n",
    "            'subcategory': None,\n",
    "            'unit': 'Energy (KWh/MWh)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'DOE'\n",
    "        },\n",
    "        {\n",
    "            'code': 'DOE_HYDROPOWER_CAPACITY',\n",
    "            'name': 'Hydropower Generation Capacity',\n",
    "            'category': 'Hydropower',\n",
    "            'subcategory': 'Hydropower',\n",
    "            'unit': 'Power (MW/KW)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'DOE'\n",
    "        },\n",
    "        {\n",
    "            'code': 'DOE_ELECTRICITY_RATES',\n",
    "            'name': 'Electricity Rates',\n",
    "            'category': 'EnergyPricing',\n",
    "            'subcategory': None,\n",
    "            'unit': 'Currency (PHP/USD)',\n",
    "            'frequency': 'Monthly',\n",
    "            'source': 'DOE'\n",
    "        },\n",
    "        \n",
    "        # Environment\n",
    "        {\n",
    "            'code': 'PSA_CO2_EMISSIONS',\n",
    "            'name': 'CO2 Emissions',\n",
    "            'category': 'Emissions',\n",
    "            'subcategory': 'GHGEmissions',\n",
    "            'unit': 'Mass (MT/Tonnes/KG)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_AIR_QUALITY',\n",
    "            'name': 'Air Quality Concentration Levels',\n",
    "            'category': 'Pollution',\n",
    "            'subcategory': 'AirQuality',\n",
    "            'unit': 'Unitless',\n",
    "            'frequency': 'Daily',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        \n",
    "        # Tourism\n",
    "        {\n",
    "            'code': 'PSA_TOURISM_EXPENDITURE',\n",
    "            'name': 'Tourism Expenditure',\n",
    "            'category': 'TourismExpenditure',\n",
    "            'subcategory': 'Expenditure',\n",
    "            'unit': 'Currency (PHP/USD)',\n",
    "            'frequency': 'Quarterly',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_TOURISM_GVA',\n",
    "            'name': 'Tourism Direct Gross Value Added',\n",
    "            'category': 'TourismEconomics',\n",
    "            'subcategory': None,\n",
    "            'unit': 'Currency (PHP/USD)',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        \n",
    "        # Income\n",
    "        {\n",
    "            'code': 'PSA_POVERTY_INCIDENCE',\n",
    "            'name': 'Poverty Incidence',\n",
    "            'category': 'Poverty',\n",
    "            'subcategory': None,\n",
    "            'unit': 'Percentage',\n",
    "            'frequency': 'Annual',\n",
    "            'source': 'PSA'\n",
    "        },\n",
    "        {\n",
    "            'code': 'PSA_HOUSEHOLD_CONSUMPTION',\n",
    "            'name': 'Household Final Consumption Expenditure',\n",
    "            'category': 'Consumption',\n",
    "            'subcategory': None,\n",
    "            'unit': 'Currency (PHP/USD)',\n",
    "            'frequency': 'Quarterly',\n",
    "            'source': 'PSA'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    standardized_indicators = []\n",
    "    for i, ind in enumerate(indicators):\n",
    "        methodology = f\"Standard {ind['source']} methodology applies. Refer to source documentation for detailed methodology.\"\n",
    "        description = f\"{ind['name']} (Source: {ind['source']}) - Derived from Philippine socioeconomic data collection standards.\"\n",
    "        \n",
    "        standardized_indicators.append({\n",
    "            'indicator_code': ind['code'],\n",
    "            'indicator_name': ind['name'],\n",
    "            'indicator_description': description,\n",
    "            'unit_of_measure': ind['unit'],\n",
    "            'data_source': ind['source'],\n",
    "            'category': ind['category'],\n",
    "            'subcategory': ind['subcategory'],\n",
    "            'methodology': methodology,\n",
    "            'frequency': ind['frequency'],\n",
    "            'source_table': 'default_philippine_data',\n",
    "            'source_column': 'derived',\n",
    "            'extraction_type': 'default',\n",
    "            'is_active': True,\n",
    "            'created_at': PROCESSING_TIMESTAMP,\n",
    "            'updated_at': PROCESSING_TIMESTAMP\n",
    "        })\n",
    "    \n",
    "    return standardized_indicators\n",
    "\n",
    "# Create default indicators\n",
    "indicator_data = create_default_philippine_indicators()\n",
    "print(f\"Created {len(indicator_data)} default Philippine indicators\")\n",
    "\n",
    "# Show distribution\n",
    "category_counts = {}\n",
    "source_counts = {}\n",
    "frequency_counts = {}\n",
    "\n",
    "for ind in indicator_data:\n",
    "    category = ind['category']\n",
    "    source = ind['data_source']\n",
    "    frequency = ind['frequency']\n",
    "    \n",
    "    category_counts[category] = category_counts.get(category, 0) + 1\n",
    "    source_counts[source] = source_counts.get(source, 0) + 1\n",
    "    frequency_counts[frequency] = frequency_counts.get(frequency, 0) + 1\n",
    "\n",
    "print(\"\\nCategory distribution:\")\n",
    "for category, count in sorted(category_counts.items()):\n",
    "    print(f\"  {category}: {count:,}\")\n",
    "\n",
    "print(\"\\nData source distribution:\")\n",
    "for source, count in sorted(source_counts.items()):\n",
    "    print(f\"  {source}: {count:,}\")\n",
    "\n",
    "print(\"\\nFrequency distribution:\")\n",
    "for frequency, count in sorted(frequency_counts.items()):\n",
    "    print(f\"  {frequency}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indicator Dimension with Explicit Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator dimension created: 15 records\n",
      "\n",
      "Sample indicators by category:\n",
      "\n",
      "Demographics:\n",
      "  - Total Population [Count (Persons/Units)] (Annual)\n",
      "\n",
      "VitalStatistics:\n",
      "  - Total Live Births [Count (Persons/Units)] (Annual)\n",
      "  - Total Deaths [Count (Persons/Units)] (Annual)\n",
      "\n",
      "Employment:\n",
      "  - Employment Rate [Percentage] (Quarterly)\n",
      "  - Unemployment Rate [Percentage] (Quarterly)\n",
      "\n",
      "Wages:\n",
      "  - Average Daily Basic Pay [Currency (PHP/USD)] (Monthly)\n",
      "\n",
      "EnergyConsumption:\n",
      "  - Total Final Energy Consumption [Energy (KWh/MWh)] (Annual)\n"
     ]
    }
   ],
   "source": [
    "# Create indicator dimension DataFrame with explicit schema\n",
    "# Define explicit schema for indicator dimension\n",
    "indicator_schema = StructType([\n",
    "    StructField(\"indicator_code\", StringType(), True),\n",
    "    StructField(\"indicator_name\", StringType(), True),\n",
    "    StructField(\"indicator_description\", StringType(), True),\n",
    "    StructField(\"unit_of_measure\", StringType(), True),\n",
    "    StructField(\"data_source\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"subcategory\", StringType(), True),\n",
    "    StructField(\"methodology\", StringType(), True),\n",
    "    StructField(\"frequency\", StringType(), True),\n",
    "    StructField(\"source_table\", StringType(), True),\n",
    "    StructField(\"source_column\", StringType(), True),\n",
    "    StructField(\"extraction_type\", StringType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "    StructField(\"updated_at\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "if indicator_data:\n",
    "    # Ensure all values are properly typed\n",
    "    clean_indicators = []\n",
    "    for ind in indicator_data:\n",
    "        clean_ind = {\n",
    "            'indicator_code': str(ind['indicator_code']) if ind['indicator_code'] else \"\",\n",
    "            'indicator_name': str(ind['indicator_name']) if ind['indicator_name'] else \"\",\n",
    "            'indicator_description': str(ind['indicator_description']) if ind['indicator_description'] else \"\",\n",
    "            'unit_of_measure': str(ind['unit_of_measure']) if ind['unit_of_measure'] else \"Unitless\",\n",
    "            'data_source': str(ind['data_source']) if ind['data_source'] else \"Unknown\",\n",
    "            'category': str(ind['category']) if ind['category'] else \"Other\",\n",
    "            'subcategory': str(ind['subcategory']) if ind.get('subcategory') else None,\n",
    "            'methodology': str(ind['methodology']) if ind['methodology'] else None,\n",
    "            'frequency': str(ind['frequency']) if ind['frequency'] else \"Annual\",\n",
    "            'source_table': str(ind['source_table']) if ind['source_table'] else \"\",\n",
    "            'source_column': str(ind['source_column']) if ind['source_column'] else \"\",\n",
    "            'extraction_type': str(ind['extraction_type']) if ind['extraction_type'] else \"unknown\",\n",
    "            'is_active': bool(ind.get('is_active', True)),\n",
    "            'created_at': ind.get('created_at'),\n",
    "            'updated_at': ind.get('updated_at')\n",
    "        }\n",
    "        clean_indicators.append(clean_ind)\n",
    "    \n",
    "    # Create DataFrame with explicit schema\n",
    "    indicators_df = spark.createDataFrame(clean_indicators, schema=indicator_schema)\n",
    "    \n",
    "    # Add indicator_id using row_number\n",
    "    window_spec = Window.orderBy(\"indicator_code\")\n",
    "    indicators_df = indicators_df.withColumn(\"indicator_id\", row_number().over(window_spec))\n",
    "    \n",
    "    # Select final columns in correct order per schema design\n",
    "    indicators_df = indicators_df.select(\n",
    "        \"indicator_id\", \"indicator_code\", \"indicator_name\", \"indicator_description\",\n",
    "        \"unit_of_measure\", \"data_source\", \"category\", \"subcategory\",\n",
    "        \"methodology\", \"frequency\", \"is_active\", \"created_at\", \"updated_at\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Indicator dimension created: {indicators_df.count():,} records\")\n",
    "    \n",
    "    # Show sample indicators by category\n",
    "    print(\"\\nSample indicators by category:\")\n",
    "    for category in list(category_counts.keys())[:5]:\n",
    "        print(f\"\\n{category}:\")\n",
    "        sample_df = indicators_df.filter(col(\"category\") == category).limit(2)\n",
    "        for row in sample_df.collect():\n",
    "            print(f\"  - {row.indicator_name} [{row.unit_of_measure}] ({row.frequency})\")\n",
    "            \n",
    "else:\n",
    "    print(\"Creating minimal sample dimension\")\n",
    "    # Create sample indicators with explicit schema\n",
    "    sample_indicators = [{\n",
    "        'indicator_code': 'POP_TOTAL',\n",
    "        'indicator_name': 'Total Population',\n",
    "        'indicator_description': 'Total Population Count (Source: PSA)',\n",
    "        'unit_of_measure': 'Count (Persons/Units)',\n",
    "        'data_source': 'PSA',\n",
    "        'category': 'Demographics',\n",
    "        'subcategory': None,\n",
    "        'methodology': 'Standard PSA methodology applies.',\n",
    "        'frequency': 'Annual',\n",
    "        'source_table': 'sample_population_table',\n",
    "        'source_column': 'population_count',\n",
    "        'extraction_type': 'sample',\n",
    "        'is_active': True,\n",
    "        'created_at': PROCESSING_TIMESTAMP,\n",
    "        'updated_at': PROCESSING_TIMESTAMP\n",
    "    }]\n",
    "    \n",
    "    indicators_df = spark.createDataFrame(sample_indicators, schema=indicator_schema)\n",
    "    \n",
    "    # Add indicator_id\n",
    "    indicators_df = indicators_df.withColumn(\"indicator_id\", lit(1).cast(LongType()))\n",
    "    \n",
    "    # Select final columns\n",
    "    indicators_df = indicators_df.select(\n",
    "        \"indicator_id\", \"indicator_code\", \"indicator_name\", \"indicator_description\",\n",
    "        \"unit_of_measure\", \"data_source\", \"category\", \"subcategory\",\n",
    "        \"methodology\", \"frequency\", \"is_active\", \"created_at\", \"updated_at\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indicator Dimension Schema:\n",
      "root\n",
      " |-- indicator_id: integer (nullable = false)\n",
      " |-- indicator_code: string (nullable = true)\n",
      " |-- indicator_name: string (nullable = true)\n",
      " |-- indicator_description: string (nullable = true)\n",
      " |-- unit_of_measure: string (nullable = true)\n",
      " |-- data_source: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- subcategory: string (nullable = true)\n",
      " |-- methodology: string (nullable = true)\n",
      " |-- frequency: string (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- updated_at: timestamp (nullable = true)\n",
      "\n",
      "\n",
      "Sample Data:\n",
      "+------------+-------------------------+---------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------+-----------+-----------------+------------+-----------------------------------------------------------------------------------------+---------+---------+--------------------------+--------------------------+\n",
      "|indicator_id|indicator_code           |indicator_name                         |indicator_description                                                                                                   |unit_of_measure      |data_source|category         |subcategory |methodology                                                                              |frequency|is_active|created_at                |updated_at                |\n",
      "+------------+-------------------------+---------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------+-----------+-----------------+------------+-----------------------------------------------------------------------------------------+---------+---------+--------------------------+--------------------------+\n",
      "|1           |DOE_ELECTRICITY_RATES    |Electricity Rates                      |Electricity Rates (Source: DOE) - Derived from Philippine socioeconomic data collection standards.                      |Currency (PHP/USD)   |DOE        |EnergyPricing    |null        |Standard DOE methodology applies. Refer to source documentation for detailed methodology.|Monthly  |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|2           |DOE_ENERGY_CONSUMPTION   |Total Final Energy Consumption         |Total Final Energy Consumption (Source: DOE) - Derived from Philippine socioeconomic data collection standards.         |Energy (KWh/MWh)     |DOE        |EnergyConsumption|null        |Standard DOE methodology applies. Refer to source documentation for detailed methodology.|Annual   |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|3           |DOE_HYDROPOWER_CAPACITY  |Hydropower Generation Capacity         |Hydropower Generation Capacity (Source: DOE) - Derived from Philippine socioeconomic data collection standards.         |Power (MW/KW)        |DOE        |Hydropower       |Hydropower  |Standard DOE methodology applies. Refer to source documentation for detailed methodology.|Annual   |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|4           |PSA_AIR_QUALITY          |Air Quality Concentration Levels       |Air Quality Concentration Levels (Source: PSA) - Derived from Philippine socioeconomic data collection standards.       |Unitless             |PSA        |Pollution        |AirQuality  |Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Daily    |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|5           |PSA_BIRTHS_TOTAL         |Total Live Births                      |Total Live Births (Source: PSA) - Derived from Philippine socioeconomic data collection standards.                      |Count (Persons/Units)|PSA        |VitalStatistics  |Births      |Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Annual   |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|6           |PSA_CO2_EMISSIONS        |CO2 Emissions                          |CO2 Emissions (Source: PSA) - Derived from Philippine socioeconomic data collection standards.                          |Mass (MT/Tonnes/KG)  |PSA        |Emissions        |GHGEmissions|Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Annual   |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|7           |PSA_DAILY_WAGE           |Average Daily Basic Pay                |Average Daily Basic Pay (Source: PSA) - Derived from Philippine socioeconomic data collection standards.                |Currency (PHP/USD)   |PSA        |Wages            |Wages       |Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Monthly  |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|8           |PSA_DEATHS_TOTAL         |Total Deaths                           |Total Deaths (Source: PSA) - Derived from Philippine socioeconomic data collection standards.                           |Count (Persons/Units)|PSA        |VitalStatistics  |Deaths      |Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Annual   |true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|9           |PSA_EMPLOYMENT_RATE      |Employment Rate                        |Employment Rate (Source: PSA) - Derived from Philippine socioeconomic data collection standards.                        |Percentage           |PSA        |Employment       |Employment  |Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Quarterly|true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "|10          |PSA_HOUSEHOLD_CONSUMPTION|Household Final Consumption Expenditure|Household Final Consumption Expenditure (Source: PSA) - Derived from Philippine socioeconomic data collection standards.|Currency (PHP/USD)   |PSA        |Consumption      |null        |Standard PSA methodology applies. Refer to source documentation for detailed methodology.|Quarterly|true     |2025-08-18 21:50:23.162899|2025-08-18 21:50:23.162899|\n",
      "+------------+-------------------------+---------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------+-----------+-----------------+------------+-----------------------------------------------------------------------------------------+---------+---------+--------------------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show comprehensive sample of the dimension\n",
    "print(\"\\nIndicator Dimension Schema:\")\n",
    "indicators_df.printSchema()\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "indicators_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Indicator Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indicator dimension saved successfully!\n",
      "Path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver/dim_indicator\n",
      "Records: 15\n"
     ]
    }
   ],
   "source": [
    "# Save indicator dimension\n",
    "dim_indicator_path = os.path.join(SILVER_PATH, \"dim_indicator\")\n",
    "\n",
    "try:\n",
    "    indicators_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .save(dim_indicator_path)\n",
    "    \n",
    "    print(f\"\\nIndicator dimension saved successfully!\")\n",
    "    print(f\"Path: {dim_indicator_path}\")\n",
    "    print(f\"Records: {indicators_df.count():,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving indicator dimension: {e}\")\n",
    "    # Try saving as parquet if delta fails\n",
    "    try:\n",
    "        parquet_path = dim_indicator_path + \"_parquet\"\n",
    "        indicators_df.write.format(\"parquet\").mode(\"overwrite\").save(parquet_path)\n",
    "        print(f\"Saved as parquet instead: {parquet_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Failed to save as parquet too: {e2}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation: Successfully created dim_indicator with 15 records\n",
      "\n",
      "Validation sample by category:\n",
      "  Demographics: 1 indicators\n",
      "  VitalStatistics: 2 indicators\n",
      "  Employment: 2 indicators\n"
     ]
    }
   ],
   "source": [
    "# Final validation\n",
    "try:\n",
    "    # Validate the saved table\n",
    "    test_df = spark.read.format(\"delta\").load(dim_indicator_path)\n",
    "    count = test_df.count()\n",
    "    print(f\"\\nValidation: Successfully created dim_indicator with {count:,} records\")\n",
    "    \n",
    "    # Show validation sample\n",
    "    print(\"\\nValidation sample by category:\")\n",
    "    for category in list(category_counts.keys())[:3]:\n",
    "        sample_count = test_df.filter(col(\"category\") == category).count()\n",
    "        print(f\"  {category}: {sample_count:,} indicators\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary report saved: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver/dim_indicator_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary report\n",
    "summary_report = {\n",
    "    'processing_timestamp': PROCESSING_TIMESTAMP.isoformat(),\n",
    "    'dimension_type': 'indicator',\n",
    "    'extraction_summary': {\n",
    "        'indicators_created': len(indicator_data),\n",
    "        'extraction_method': 'default_philippine_indicators'\n",
    "    },\n",
    "    'data_source_distribution': source_counts,\n",
    "    'category_distribution': category_counts,\n",
    "    'frequency_distribution': frequency_counts,\n",
    "    'features': [\n",
    "        'Comprehensive Philippine socioeconomic indicators',\n",
    "        'Multi-domain coverage (demographics, labor, energy, environment, tourism)',\n",
    "        'Standardized categorization system',\n",
    "        'Unit of measure classification',\n",
    "        'Frequency specification',\n",
    "        'Methodology documentation',\n",
    "        'Quality validation'\n",
    "    ],\n",
    "    'output_path': dim_indicator_path,\n",
    "    'status': 'completed'\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = os.path.join(SILVER_PATH, \"dim_indicator_summary.json\")\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nSummary report saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INDICATOR DIMENSION PROCESSING SUMMARY\n",
      "======================================================================\n",
      "Processing completed: 2025-08-18 21:50:23.162899\n",
      "Indicators created: 15\n",
      "\n",
      "Data sources covered:\n",
      "  DOE: 3 indicators\n",
      "  PSA: 12 indicators\n",
      "\n",
      "Categories:\n",
      "  Consumption: 1 indicators\n",
      "  Demographics: 1 indicators\n",
      "  Emissions: 1 indicators\n",
      "  Employment: 2 indicators\n",
      "  EnergyConsumption: 1 indicators\n",
      "  EnergyPricing: 1 indicators\n",
      "  Hydropower: 1 indicators\n",
      "  Pollution: 1 indicators\n",
      "  Poverty: 1 indicators\n",
      "  TourismEconomics: 1 indicators\n",
      "  TourismExpenditure: 1 indicators\n",
      "  VitalStatistics: 2 indicators\n",
      "  Wages: 1 indicators\n",
      "\n",
      "Frequencies:\n",
      "  Annual: 8 indicators\n",
      "  Daily: 1 indicators\n",
      "  Monthly: 2 indicators\n",
      "  Quarterly: 4 indicators\n",
      "\n",
      "Output path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver/dim_indicator\n",
      "Indicator dimension ready for fact table joins!\n",
      "\n",
      "Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "# Summary and cleanup\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"INDICATOR DIMENSION PROCESSING SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Processing completed: {PROCESSING_TIMESTAMP}\")\n",
    "print(f\"Indicators created: {len(indicator_data):,}\")\n",
    "print(f\"\")\n",
    "print(\"Data sources covered:\")\n",
    "for source, count in sorted(source_counts.items()):\n",
    "    print(f\"  {source}: {count:,} indicators\")\n",
    "print(f\"\")\n",
    "print(\"Categories:\")\n",
    "for category, count in sorted(category_counts.items()):\n",
    "    print(f\"  {category}: {count:,} indicators\")\n",
    "print(f\"\")\n",
    "print(\"Frequencies:\")\n",
    "for frequency, count in sorted(frequency_counts.items()):\n",
    "    print(f\"  {frequency}: {count:,} indicators\")\n",
    "print(f\"\")\n",
    "print(f\"Output path: {dim_indicator_path}\")\n",
    "print(\"Indicator dimension ready for fact table joins!\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"\\nSpark session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
