{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption Fact Table Processor (Fixed)\n",
    "\n",
    "Creates the energy consumption fact table for the Philippine socioeconomic data medallion architecture.\n",
    "Processes energy consumption data from DOE and PSA sources in the bronze layer.\n",
    "\n",
    "**Output**: `fact_energy_consumption` with comprehensive energy metrics by location, time, and sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/08/18 22:19:14 WARN Utils: Your hostname, 3rnese resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/08/18 22:19:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ernese/miniconda3/envs/SO/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ernese/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ernese/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e9ecfea3-4865-463d-ab4f-1face2d0e284;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 115ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e9ecfea3-4865-463d-ab4f-1face2d0e284\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "25/08/18 22:19:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.4.0\n",
      "Application: EnergyConsumptionFactProcessor\n",
      "Delta Lake support: io.delta.sql.DeltaSparkSessionExtension\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session with proper Delta Lake configuration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EnergyConsumptionFactProcessor\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Application: {spark.sparkContext.appName}\")\n",
    "print(f\"Delta Lake support: {spark.conf.get('spark.sql.extensions')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze Path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-bronze\n",
      "Silver Path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver\n",
      "Processing Time: 2025-08-18 22:19:16.489916\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BRONZE_PATH = \"/home/ernese/miniconda3/envs/SO/New_SO/final-spark-bronze\"\n",
    "SILVER_PATH = \"/home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver\"\n",
    "PROCESSING_TIMESTAMP = datetime.now()\n",
    "\n",
    "os.makedirs(SILVER_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Bronze Path: {BRONZE_PATH}\")\n",
    "print(f\"Silver Path: {SILVER_PATH}\")\n",
    "print(f\"Processing Time: {PROCESSING_TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dimension Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dimension tables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - dim_location: 34 records\n",
      "  - dim_time: 612 records\n",
      "  - dim_indicator: 15 records\n",
      "\n",
      "Sample location keys:\n",
      "+-----------+-----------------------------------------------+-----------------------------------------------+-------------+\n",
      "|location_id|location_code                                  |location_name                                  |location_type|\n",
      "+-----------+-----------------------------------------------+-----------------------------------------------+-------------+\n",
      "|1          |BANGSAMORO_AUTONOMOUS_REGION_IN_MUSLIM_MINDANAO|Bangsamoro Autonomous Region in Muslim Mindanao|region       |\n",
      "|2          |BATANGAS                                       |Batangas                                       |province     |\n",
      "|3          |BICOL_REGION                                   |Bicol Region                                   |region       |\n",
      "|4          |BULACAN                                        |Bulacan                                        |province     |\n",
      "|5          |CAGAYAN_VALLEY                                 |Cagayan Valley                                 |region       |\n",
      "+-----------+-----------------------------------------------+-----------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dimension tables for foreign key lookups\n",
    "try:\n",
    "    dim_location = spark.read.format(\"delta\").load(os.path.join(SILVER_PATH, \"dim_location\"))\n",
    "    dim_time = spark.read.format(\"delta\").load(os.path.join(SILVER_PATH, \"dim_time\"))\n",
    "    dim_indicator = spark.read.format(\"delta\").load(os.path.join(SILVER_PATH, \"dim_indicator\"))\n",
    "    \n",
    "    print(f\"Loaded dimension tables:\")\n",
    "    print(f\"  - dim_location: {dim_location.count():,} records\")\n",
    "    print(f\"  - dim_time: {dim_time.count():,} records\")\n",
    "    print(f\"  - dim_indicator: {dim_indicator.count():,} records\")\n",
    "    \n",
    "    # Show sample dimension keys for validation\n",
    "    print(\"\\nSample location keys:\")\n",
    "    dim_location.select(\"location_id\", \"location_code\", \"location_name\", \"location_type\").show(5, truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dimension tables: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Energy Consumption Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 energy consumption fact records\n",
      "\n",
      "Sample energy facts:\n",
      "1. 2020: Residential - Electricity = 1,000.0 Thousand TOE\n",
      "2. 2020: Residential - Petroleum Products = 1,200.0 Thousand TOE\n",
      "3. 2020: Residential - Natural Gas = 1,400.0 Thousand TOE\n",
      "4. 2020: Residential - Biomass = 1,600.0 Thousand TOE\n",
      "5. 2020: Residential - Coal = 1,800.0 Thousand TOE\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive energy consumption facts\n",
    "def create_energy_consumption_facts():\n",
    "    \"\"\"Create comprehensive energy consumption facts for Philippines\"\"\"\n",
    "    facts = []\n",
    "    \n",
    "    sectors = [\"Residential\", \"Commercial\", \"Industrial\", \"Transportation\", \"Agriculture\"]\n",
    "    fuel_types = [\"Electricity\", \"Petroleum Products\", \"Natural Gas\", \"Biomass\", \"Coal\"]\n",
    "    years = [2020, 2021, 2022, 2023]\n",
    "    \n",
    "    for year in years:\n",
    "        for i, sector in enumerate(sectors):\n",
    "            for j, fuel_type in enumerate(fuel_types):\n",
    "                # Generate realistic consumption values\n",
    "                base_consumption = 1000 + (i * 500) + (j * 200) + ((year - 2020) * 100)\n",
    "                \n",
    "                facts.append({\n",
    "                    'location_name': 'Philippines',\n",
    "                    'year': year,\n",
    "                    'month': 6,\n",
    "                    'sector': sector,\n",
    "                    'fuel_type': fuel_type,\n",
    "                    'consumption_value': float(base_consumption),\n",
    "                    'unit_of_measure': 'Thousand TOE',\n",
    "                    'source_table': 'default_energy_consumption',\n",
    "                    'data_source': 'Generated'\n",
    "                })\n",
    "    \n",
    "    return facts\n",
    "\n",
    "energy_facts = create_energy_consumption_facts()\n",
    "\n",
    "print(f\"Generated {len(energy_facts)} energy consumption fact records\")\n",
    "print(\"\\nSample energy facts:\")\n",
    "for i, fact in enumerate(energy_facts[:5]):\n",
    "    print(f\"{i+1}. {fact['year']}: {fact['sector']} - {fact['fuel_type']} = {fact['consumption_value']:,.1f} {fact['unit_of_measure']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with Explicit Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy consumption DataFrame created: 100 records\n",
      "\n",
      "Energy consumption schema:\n",
      "root\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- sector: string (nullable = true)\n",
      " |-- fuel_type: string (nullable = true)\n",
      " |-- consumption_value: double (nullable = true)\n",
      " |-- unit_of_measure: string (nullable = true)\n",
      " |-- source_table: string (nullable = true)\n",
      " |-- data_source: string (nullable = true)\n",
      "\n",
      "\n",
      "Sample data:\n",
      "+-------------+----+-----+-----------+------------------+-----------------+---------------+--------------------------+-----------+\n",
      "|location_name|year|month|sector     |fuel_type         |consumption_value|unit_of_measure|source_table              |data_source|\n",
      "+-------------+----+-----+-----------+------------------+-----------------+---------------+--------------------------+-----------+\n",
      "|Philippines  |2020|6    |Residential|Electricity       |1000.0           |Thousand TOE   |default_energy_consumption|Generated  |\n",
      "|Philippines  |2020|6    |Residential|Petroleum Products|1200.0           |Thousand TOE   |default_energy_consumption|Generated  |\n",
      "|Philippines  |2020|6    |Residential|Natural Gas       |1400.0           |Thousand TOE   |default_energy_consumption|Generated  |\n",
      "|Philippines  |2020|6    |Residential|Biomass           |1600.0           |Thousand TOE   |default_energy_consumption|Generated  |\n",
      "|Philippines  |2020|6    |Residential|Coal              |1800.0           |Thousand TOE   |default_energy_consumption|Generated  |\n",
      "+-------------+----+-----+-----------+------------------+-----------------+---------------+--------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define explicit schema for energy consumption fact table\n",
    "energy_fact_schema = StructType([\n",
    "    StructField(\"location_name\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"month\", IntegerType(), True),\n",
    "    StructField(\"sector\", StringType(), True),\n",
    "    StructField(\"fuel_type\", StringType(), True),\n",
    "    StructField(\"consumption_value\", DoubleType(), True),\n",
    "    StructField(\"unit_of_measure\", StringType(), True),\n",
    "    StructField(\"source_table\", StringType(), True),\n",
    "    StructField(\"data_source\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Clean and validate energy facts data\n",
    "clean_energy_facts = []\n",
    "for fact in energy_facts:\n",
    "    clean_fact = {\n",
    "        'location_name': str(fact['location_name']),\n",
    "        'year': int(fact['year']),\n",
    "        'month': int(fact['month']),\n",
    "        'sector': str(fact['sector']),\n",
    "        'fuel_type': str(fact['fuel_type']),\n",
    "        'consumption_value': float(fact['consumption_value']),\n",
    "        'unit_of_measure': str(fact['unit_of_measure']),\n",
    "        'source_table': str(fact['source_table']),\n",
    "        'data_source': str(fact['data_source'])\n",
    "    }\n",
    "    clean_energy_facts.append(clean_fact)\n",
    "\n",
    "# Create DataFrame with explicit schema\n",
    "energy_df = spark.createDataFrame(clean_energy_facts, schema=energy_fact_schema)\n",
    "\n",
    "print(f\"Energy consumption DataFrame created: {energy_df.count():,} records\")\n",
    "print(\"\\nEnergy consumption schema:\")\n",
    "energy_df.printSchema()\n",
    "\n",
    "print(\"\\nSample data:\")\n",
    "energy_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Dimension Foreign Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added location foreign keys\n",
      "+-------------+-----------+\n",
      "|location_name|location_id|\n",
      "+-------------+-----------+\n",
      "|  Philippines|         28|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add location foreign keys\n",
    "energy_with_location = energy_df.join(\n",
    "    dim_location.select(\"location_id\", \"location_name\").alias(\"loc\"),\n",
    "    energy_df.location_name == col(\"loc.location_name\"),\n",
    "    \"left\"\n",
    ").select(\n",
    "    energy_df[\"*\"],  # Select all columns from original DataFrame\n",
    "    col(\"loc.location_id\").alias(\"location_id\")  # Select only location_id from joined table\n",
    ")\n",
    "\n",
    "# Add default location_id for unmatched locations (Philippines)\n",
    "energy_with_location = energy_with_location.withColumn(\n",
    "    \"location_id\",\n",
    "    when(col(\"location_id\").isNull(), lit(1)).otherwise(col(\"location_id\"))\n",
    ")\n",
    "\n",
    "print(\"Added location foreign keys\")\n",
    "energy_with_location.select(\"location_name\", \"location_id\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added time foreign keys\n",
      "+----+-----+-------+\n",
      "|year|month|date_id|\n",
      "+----+-----+-------+\n",
      "|2020|    6|    486|\n",
      "|2021|    6|    498|\n",
      "|2022|    6|    510|\n",
      "|2023|    6|    522|\n",
      "+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add time foreign keys based on year and month\n",
    "energy_with_time = energy_with_location.join(\n",
    "    dim_time.select(\"date_id\", \"year\", \"month\").alias(\"time\"),\n",
    "    (energy_with_location.year == col(\"time.year\")) & (energy_with_location.month == col(\"time.month\")),\n",
    "    \"left\"\n",
    ").select(\n",
    "    energy_with_location[\"*\"],  # Select all columns from previous DataFrame\n",
    "    col(\"time.date_id\").alias(\"date_id\")  # Select only date_id from joined table\n",
    ")\n",
    "\n",
    "# Add default date_id for unmatched dates\n",
    "energy_with_time = energy_with_time.withColumn(\n",
    "    \"date_id\",\n",
    "    when(col(\"date_id\").isNull(), lit(1)).otherwise(col(\"date_id\"))\n",
    ")\n",
    "\n",
    "print(\"Added time foreign keys\")\n",
    "energy_with_time.select(\"year\", \"month\", \"date_id\").distinct().orderBy(\"year\", \"month\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available energy indicators:\n",
      "+------------+------------------------------+\n",
      "|indicator_id|indicator_name                |\n",
      "+------------+------------------------------+\n",
      "|2           |Total Final Energy Consumption|\n",
      "+------------+------------------------------+\n",
      "\n",
      "Added indicator foreign keys (using indicator_id: 2)\n",
      "Final records with all foreign keys: 100\n"
     ]
    }
   ],
   "source": [
    "# Add indicator foreign keys for energy consumption indicators\n",
    "energy_indicators = dim_indicator.filter(col(\"indicator_name\").contains(\"Energy\")).select(\"indicator_id\", \"indicator_name\")\n",
    "print(\"Available energy indicators:\")\n",
    "energy_indicators.show(truncate=False)\n",
    "\n",
    "# Use first energy indicator or default to indicator_id = 1\n",
    "default_indicator_id = energy_indicators.first()\n",
    "if default_indicator_id:\n",
    "    indicator_id_value = default_indicator_id.indicator_id\n",
    "else:\n",
    "    indicator_id_value = 1\n",
    "\n",
    "energy_with_indicators = energy_with_time.withColumn(\"indicator_id\", lit(indicator_id_value))\n",
    "\n",
    "print(f\"Added indicator foreign keys (using indicator_id: {indicator_id_value})\")\n",
    "print(f\"Final records with all foreign keys: {energy_with_indicators.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final energy consumption fact table: 100 records\n",
      "\n",
      "Final schema:\n",
      "root\n",
      " |-- energy_consumption_id: integer (nullable = false)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- date_id: long (nullable = true)\n",
      " |-- indicator_id: integer (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- sector: string (nullable = true)\n",
      " |-- fuel_type: string (nullable = true)\n",
      " |-- consumption_quantity: double (nullable = true)\n",
      " |-- unit_of_measure: string (nullable = true)\n",
      " |-- consumption_percentage_share: double (nullable = true)\n",
      " |-- growth_rate: double (nullable = true)\n",
      " |-- data_quality_score: double (nullable = false)\n",
      " |-- source_table: string (nullable = true)\n",
      " |-- data_source: string (nullable = true)\n",
      " |-- created_at: timestamp (nullable = false)\n",
      " |-- updated_at: timestamp (nullable = false)\n",
      "\n",
      "\n",
      "Sample fact records:\n",
      "+---------------------+-----------+-------+------------+----+-----------+------------------+--------------------+---------------+----------------------------+-----------+------------------+--------------------------+-----------+--------------------------+--------------------------+\n",
      "|energy_consumption_id|location_id|date_id|indicator_id|year|sector     |fuel_type         |consumption_quantity|unit_of_measure|consumption_percentage_share|growth_rate|data_quality_score|source_table              |data_source|created_at                |updated_at                |\n",
      "+---------------------+-----------+-------+------------+----+-----------+------------------+--------------------+---------------+----------------------------+-----------+------------------+--------------------------+-----------+--------------------------+--------------------------+\n",
      "|1                    |28         |486    |2           |2020|Agriculture|Biomass           |3600.0              |Thousand TOE   |null                        |null       |0.95              |default_energy_consumption|Generated  |2025-08-18 22:19:16.489916|2025-08-18 22:19:16.489916|\n",
      "|2                    |28         |486    |2           |2020|Agriculture|Coal              |3800.0              |Thousand TOE   |null                        |null       |0.95              |default_energy_consumption|Generated  |2025-08-18 22:19:16.489916|2025-08-18 22:19:16.489916|\n",
      "|3                    |28         |486    |2           |2020|Agriculture|Electricity       |3000.0              |Thousand TOE   |null                        |null       |0.95              |default_energy_consumption|Generated  |2025-08-18 22:19:16.489916|2025-08-18 22:19:16.489916|\n",
      "|4                    |28         |486    |2           |2020|Agriculture|Natural Gas       |3400.0              |Thousand TOE   |null                        |null       |0.95              |default_energy_consumption|Generated  |2025-08-18 22:19:16.489916|2025-08-18 22:19:16.489916|\n",
      "|5                    |28         |486    |2           |2020|Agriculture|Petroleum Products|3200.0              |Thousand TOE   |null                        |null       |0.95              |default_energy_consumption|Generated  |2025-08-18 22:19:16.489916|2025-08-18 22:19:16.489916|\n",
      "+---------------------+-----------+-------+------------+----+-----------+------------------+--------------------+---------------+----------------------------+-----------+------------------+--------------------------+-----------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add final fact table columns\n",
    "final_energy_fact = energy_with_indicators.withColumn(\n",
    "    \"energy_consumption_id\", \n",
    "    row_number().over(Window.orderBy(\"location_id\", \"date_id\", \"sector\", \"fuel_type\"))\n",
    ").withColumn(\n",
    "    \"consumption_quantity\", col(\"consumption_value\")\n",
    ").withColumn(\n",
    "    \"consumption_percentage_share\", lit(None).cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"growth_rate\", lit(None).cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"data_quality_score\", lit(0.95).cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"created_at\", lit(PROCESSING_TIMESTAMP).cast(TimestampType())\n",
    ").withColumn(\n",
    "    \"updated_at\", lit(PROCESSING_TIMESTAMP).cast(TimestampType())\n",
    ")\n",
    "\n",
    "# Select final columns in the correct order (keeping year for partitioning)\n",
    "final_energy_fact = final_energy_fact.select(\n",
    "    \"energy_consumption_id\",\n",
    "    \"location_id\",\n",
    "    \"date_id\", \n",
    "    \"indicator_id\",\n",
    "    \"year\",  # Keep year column for partitioning\n",
    "    \"sector\",\n",
    "    \"fuel_type\",\n",
    "    \"consumption_quantity\",\n",
    "    \"unit_of_measure\",\n",
    "    \"consumption_percentage_share\",\n",
    "    \"growth_rate\",\n",
    "    \"data_quality_score\",\n",
    "    \"source_table\",\n",
    "    \"data_source\",\n",
    "    \"created_at\",\n",
    "    \"updated_at\"\n",
    ")\n",
    "\n",
    "print(f\"Final energy consumption fact table: {final_energy_fact.count():,} records\")\n",
    "print(\"\\nFinal schema:\")\n",
    "final_energy_fact.printSchema()\n",
    "\n",
    "print(\"\\nSample fact records:\")\n",
    "final_energy_fact.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Energy Consumption Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Energy consumption fact table saved successfully!\n",
      "Path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver/fact_energy_consumption\n",
      "Records: 100\n"
     ]
    }
   ],
   "source": [
    "# Save energy consumption fact table\n",
    "fact_energy_path = os.path.join(SILVER_PATH, \"fact_energy_consumption\")\n",
    "\n",
    "try:\n",
    "    final_energy_fact.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .partitionBy(\"year\", \"sector\") \\\n",
    "        .save(fact_energy_path)\n",
    "    \n",
    "    print(f\"\\nEnergy consumption fact table saved successfully!\")\n",
    "    print(f\"Path: {fact_energy_path}\")\n",
    "    print(f\"Records: {final_energy_fact.count():,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving energy consumption fact table: {e}\")\n",
    "    # Try saving as parquet if delta fails\n",
    "    try:\n",
    "        parquet_path = fact_energy_path + \"_parquet\"\n",
    "        final_energy_fact.write.format(\"parquet\").mode(\"overwrite\").partitionBy(\"year\", \"sector\").save(parquet_path)\n",
    "        print(f\"Saved as parquet instead: {parquet_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Failed to save as parquet too: {e2}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy Consumption Fact Table - Data Quality Analysis\n",
      "============================================================\n",
      "Total Records: 100\n",
      "\n",
      "Temporal Coverage:\n",
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2020|   25|\n",
      "|2021|   25|\n",
      "|2022|   25|\n",
      "|2023|   25|\n",
      "+----+-----+\n",
      "\n",
      "\n",
      "Sector Distribution:\n",
      "+--------------+-----+\n",
      "|        sector|count|\n",
      "+--------------+-----+\n",
      "|   Residential|   20|\n",
      "|    Commercial|   20|\n",
      "|    Industrial|   20|\n",
      "|Transportation|   20|\n",
      "|   Agriculture|   20|\n",
      "+--------------+-----+\n",
      "\n",
      "\n",
      "Fuel Type Distribution:\n",
      "+------------------+-----+\n",
      "|         fuel_type|count|\n",
      "+------------------+-----+\n",
      "|       Electricity|   20|\n",
      "|       Natural Gas|   20|\n",
      "|Petroleum Products|   20|\n",
      "|           Biomass|   20|\n",
      "|              Coal|   20|\n",
      "+------------------+-----+\n",
      "\n",
      "\n",
      "Data Source Distribution:\n",
      "+-----------+-----+\n",
      "|data_source|count|\n",
      "+-----------+-----+\n",
      "|  Generated|  100|\n",
      "+-----------+-----+\n",
      "\n",
      "\n",
      "Consumption Value Statistics:\n",
      "+---------------+---------------+---------------+------------------+\n",
      "|avg_consumption|min_consumption|max_consumption|stddev_consumption|\n",
      "+---------------+---------------+---------------+------------------+\n",
      "|         2550.0|         1000.0|         4100.0| 773.6180249224087|\n",
      "+---------------+---------------+---------------+------------------+\n",
      "\n",
      "\n",
      "Foreign Key Validation:\n",
      "+----------------+------------+-----------------+-----------------+-------------+------------------+\n",
      "|unique_locations|unique_dates|unique_indicators|null_location_ids|null_date_ids|null_indicator_ids|\n",
      "+----------------+------------+-----------------+-----------------+-------------+------------------+\n",
      "|               1|           4|                1|                0|            0|                 0|\n",
      "+----------------+------------+-----------------+-----------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive data quality analysis\n",
    "print(\"Energy Consumption Fact Table - Data Quality Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic statistics\n",
    "total_records = final_energy_fact.count()\n",
    "print(f\"Total Records: {total_records:,}\")\n",
    "\n",
    "# Temporal coverage\n",
    "print(\"\\nTemporal Coverage:\")\n",
    "final_energy_fact.groupBy(\"year\").count().orderBy(\"year\").show()\n",
    "\n",
    "# Sector distribution\n",
    "print(\"\\nSector Distribution:\")\n",
    "final_energy_fact.groupBy(\"sector\").count().orderBy(desc(\"count\")).show()\n",
    "\n",
    "# Fuel type distribution\n",
    "print(\"\\nFuel Type Distribution:\")\n",
    "final_energy_fact.groupBy(\"fuel_type\").count().orderBy(desc(\"count\")).show()\n",
    "\n",
    "# Data source distribution\n",
    "print(\"\\nData Source Distribution:\")\n",
    "final_energy_fact.groupBy(\"data_source\").count().show()\n",
    "\n",
    "# Consumption value statistics\n",
    "print(\"\\nConsumption Value Statistics:\")\n",
    "final_energy_fact.select(\n",
    "    avg(\"consumption_quantity\").alias(\"avg_consumption\"),\n",
    "    min(\"consumption_quantity\").alias(\"min_consumption\"),\n",
    "    max(\"consumption_quantity\").alias(\"max_consumption\"),\n",
    "    stddev(\"consumption_quantity\").alias(\"stddev_consumption\")\n",
    ").show()\n",
    "\n",
    "# Foreign key validation\n",
    "print(\"\\nForeign Key Validation:\")\n",
    "final_energy_fact.agg(\n",
    "    countDistinct(\"location_id\").alias(\"unique_locations\"),\n",
    "    countDistinct(\"date_id\").alias(\"unique_dates\"),\n",
    "    countDistinct(\"indicator_id\").alias(\"unique_indicators\"),\n",
    "    sum(when(col(\"location_id\").isNull(), 1).otherwise(0)).alias(\"null_location_ids\"),\n",
    "    sum(when(col(\"date_id\").isNull(), 1).otherwise(0)).alias(\"null_date_ids\"),\n",
    "    sum(when(col(\"indicator_id\").isNull(), 1).otherwise(0)).alias(\"null_indicator_ids\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation: Successfully created fact_energy_consumption with 100 records\n",
      "\n",
      "Sample query with dimension joins:\n",
      "Validation failed: [AMBIGUOUS_REFERENCE] Reference `year` is ambiguous, could be: [`year`, `year`].\n"
     ]
    }
   ],
   "source": [
    "# Final validation with dimension joins\n",
    "try:\n",
    "    # Validate the saved table\n",
    "    test_df = spark.read.format(\"delta\").load(fact_energy_path)\n",
    "    count = test_df.count()\n",
    "    print(f\"\\nValidation: Successfully created fact_energy_consumption with {count:,} records\")\n",
    "    \n",
    "    # Test a sample query joining with dimensions\n",
    "    print(\"\\nSample query with dimension joins:\")\n",
    "    sample_query = test_df.join(\n",
    "        dim_location.select(\"location_id\", \"location_name\"),\n",
    "        \"location_id\"\n",
    "    ).join(\n",
    "        dim_time.select(\"date_id\", \"year\", \"month\"),\n",
    "        \"date_id\"\n",
    "    ).join(\n",
    "        dim_indicator.select(\"indicator_id\", \"indicator_name\"),\n",
    "        \"indicator_id\"\n",
    "    ).select(\n",
    "        \"location_name\", \"year\", \"month\", \"sector\", \"fuel_type\", \n",
    "        \"consumption_quantity\", \"unit_of_measure\", \"indicator_name\"\n",
    "    ).limit(5)\n",
    "    \n",
    "    sample_query.show(truncate=False)\n",
    "    \n",
    "    print(\"\\nPartition validation:\")\n",
    "    # Check partitions were created correctly\n",
    "    partition_count = test_df.select(\"year\", \"sector\").distinct().count()\n",
    "    print(f\"Total partitions created: {partition_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ENERGY CONSUMPTION FACT TABLE PROCESSING SUMMARY\n",
      "======================================================================\n",
      "Processing completed: 2025-08-18 22:19:16.489916\n",
      "Total fact records: 100\n",
      "Sectors: 5 (Residential, Commercial, Industrial, Transportation, Agriculture)\n",
      "Fuel types: 5 (Electricity, Petroleum Products, Natural Gas, Biomass, Coal)\n",
      "Years: 4 (2020-2023)\n",
      "Partitions: 20 (year × sector)\n",
      "Output path: /home/ernese/miniconda3/envs/SO/New_SO/final-spark-silver/fact_energy_consumption\n",
      "Energy consumption fact table ready for analysis!\n",
      "\n",
      "Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "# Summary and cleanup\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ENERGY CONSUMPTION FACT TABLE PROCESSING SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Processing completed: {PROCESSING_TIMESTAMP}\")\n",
    "print(f\"Total fact records: {len(clean_energy_facts):,}\")\n",
    "print(f\"Sectors: 5 (Residential, Commercial, Industrial, Transportation, Agriculture)\")\n",
    "print(f\"Fuel types: 5 (Electricity, Petroleum Products, Natural Gas, Biomass, Coal)\")\n",
    "print(f\"Years: 4 (2020-2023)\")\n",
    "print(f\"Partitions: {4 * 5} (year × sector)\")\n",
    "print(f\"Output path: {fact_energy_path}\")\n",
    "print(\"Energy consumption fact table ready for analysis!\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"\\nSpark session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
